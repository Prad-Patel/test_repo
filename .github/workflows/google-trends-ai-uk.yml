name: Google Trends AI Small Business UK

on:
  workflow_dispatch:
  schedule:
    # Run weekly on Mondays at 9:00 AM UTC
    - cron: '0 9 * * 1'

env:
  TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
  TELEGRAM_CHANNEL_ID: ${{ secrets.TELEGRAM_CHANNEL_ID }}

jobs:
  investigate-trends:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install pytrends pandas tabulate requests

      - name: Investigate Google Trends for AI in UK
        run: |
          python << 'EOF' | tee google_trends_report.txt
          from pytrends.request import TrendReq
          import pandas as pd
          from tabulate import tabulate
          from datetime import datetime
          import time
          import random

          def create_pytrends():
              """Create pytrends instance with browser-like settings"""
              return TrendReq(
                  hl='en-GB',
                  tz=0,
                  timeout=(10, 30),
                  retries=2,
                  backoff_factor=0.5,
                  requests_args={'headers': {
                      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
                  }}
              )

          def retry_with_backoff(func, description, max_retries=3, base_delay=15):
              """Retry function with exponential backoff"""
              for attempt in range(max_retries):
                  try:
                      if attempt > 0:
                          delay = base_delay * (2 ** (attempt - 1)) + random.uniform(5, 15)
                          print(f"  Retry {attempt}/{max_retries} for {description} after {delay:.0f}s...")
                          time.sleep(delay)
                      return func()
                  except Exception as e:
                      error_msg = str(e)
                      if attempt == max_retries - 1:
                          print(f"  Failed after {max_retries} attempts: {error_msg}")
                          return None
                      if '429' in error_msg:
                          print(f"  Rate limited on attempt {attempt + 1}, will retry...")
                      else:
                          print(f"  Error on attempt {attempt + 1}: {error_msg}")
              return None

          print("=" * 60)
          print("GOOGLE TRENDS: AI & SMALL BUSINESS UK")
          print(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC")
          print("=" * 60)

          # Keywords focused on AI impact on small businesses
          ai_keywords = ['AI small business', 'AI for business', 'ChatGPT business']

          # 1. Interest Over Time Analysis
          print("\n" + "=" * 60)
          print("1. AI + SMALL BUSINESS INTEREST (Past 12 Months - UK)")
          print("=" * 60)

          def fetch_interest():
              pt = create_pytrends()
              pt.build_payload(ai_keywords, cat=0, timeframe='today 12-m', geo='GB')
              return pt.interest_over_time()

          data = retry_with_backoff(fetch_interest, "interest over time")
          if data is not None and not data.empty:
              avg_interest = data.drop('isPartial', axis=1, errors='ignore').mean().sort_values(ascending=False)
              print("\nAverage Search Interest (0-100 scale):")
              print("-" * 45)
              for keyword, value in avg_interest.items():
                  bar = "â–ˆ" * int(value / 5)
                  print(f"{keyword:25} | {value:5.1f} | {bar}")

              print("\nMost Recent Week:")
              print("-" * 45)
              recent = data.drop('isPartial', axis=1, errors='ignore').tail(1)
              for col in recent.columns:
                  print(f"{col:25} | {recent[col].values[0]:5.0f}")
          else:
              print("Could not retrieve interest data.")

          # Long pause between requests
          print("\nWaiting before next request...")
          time.sleep(30 + random.uniform(5, 15))

          # 2. Related Queries for AI small business
          print("\n" + "=" * 60)
          print("2. RELATED QUERIES FOR 'AI SMALL BUSINESS' IN UK")
          print("=" * 60)

          def fetch_ai_smb_related():
              pt = create_pytrends()
              pt.build_payload(['AI small business'], cat=0, timeframe='today 12-m', geo='GB')
              return pt.related_queries()

          related = retry_with_backoff(fetch_ai_smb_related, "AI small business related queries")
          if related and 'AI small business' in related:
              smb_data = related['AI small business']

              if smb_data.get('top') is not None and not smb_data['top'].empty:
                  print("\nTop Related Queries:")
                  print("-" * 45)
                  print(tabulate(smb_data['top'].head(10), headers='keys', tablefmt='simple', showindex=False))

              if smb_data.get('rising') is not None and not smb_data['rising'].empty:
                  print("\nRising Queries (Breakout trends):")
                  print("-" * 45)
                  print(tabulate(smb_data['rising'].head(10), headers='keys', tablefmt='simple', showindex=False))
          else:
              print("Could not retrieve related queries.")

          # Long pause between requests
          print("\nWaiting before next request...")
          time.sleep(30 + random.uniform(5, 15))

          # 3. Related Queries for AI automation
          print("\n" + "=" * 60)
          print("3. RELATED QUERIES FOR 'AI AUTOMATION BUSINESS' IN UK")
          print("=" * 60)

          def fetch_automation_related():
              pt = create_pytrends()
              pt.build_payload(['AI automation business'], cat=0, timeframe='today 12-m', geo='GB')
              return pt.related_queries()

          auto_related = retry_with_backoff(fetch_automation_related, "AI automation related queries")
          if auto_related and 'AI automation business' in auto_related:
              auto_data = auto_related['AI automation business']

              if auto_data.get('top') is not None and not auto_data['top'].empty:
                  print("\nTop Related Queries:")
                  print("-" * 45)
                  print(tabulate(auto_data['top'].head(10), headers='keys', tablefmt='simple', showindex=False))

              if auto_data.get('rising') is not None and not auto_data['rising'].empty:
                  print("\nRising Queries (Breakout trends):")
                  print("-" * 45)
                  print(tabulate(auto_data['rising'].head(10), headers='keys', tablefmt='simple', showindex=False))
          else:
              print("Could not retrieve related queries.")

          # Summary
          print("\n" + "=" * 60)
          print("SUMMARY")
          print("=" * 60)
          print("""
          This report shows AI + Small Business search trends in the UK.
          Focus: How AI is impacting small businesses
          - Interest: 0-100 scale (relative to peak)
          - Rising: Queries gaining significant traction
          - Data: Google Trends API
          """)

          print("=" * 60)
          print("END OF REPORT")
          print("=" * 60)
          EOF

      - name: Send report to Telegram
        run: |
          python << 'EOF'
          import requests
          import os

          BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
          CHANNEL_ID = os.environ.get('TELEGRAM_CHANNEL_ID')

          if not BOT_TOKEN or not CHANNEL_ID:
              print("Error: Telegram credentials not configured")
              exit(1)

          # Read the report
          with open('google_trends_report.txt', 'r') as f:
              report = f.read()

          # Telegram has a 4096 character limit per message
          MAX_LENGTH = 4000

          def send_message(text):
              url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
              payload = {
                  "chat_id": CHANNEL_ID,
                  "text": text,
                  "parse_mode": "HTML"
              }
              response = requests.post(url, json=payload)
              return response.json()

          # Send header
          header = "<b>ðŸ¤– AI & Small Business UK - Weekly Trends Report</b>\n\n"

          # Split report into chunks
          chunks = []
          current_chunk = header

          for line in report.split('\n'):
              # Escape HTML special characters
              line = line.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')

              if len(current_chunk) + len(line) + 1 > MAX_LENGTH:
                  chunks.append(current_chunk)
                  current_chunk = ""
              current_chunk += line + '\n'

          if current_chunk:
              chunks.append(current_chunk)

          # Send each chunk
          print(f"Sending report in {len(chunks)} message(s)...")
          for i, chunk in enumerate(chunks):
              formatted_chunk = f"<pre>{chunk}</pre>" if i > 0 else header + f"<pre>{chunk.replace(header, '')}</pre>"

              result = send_message(formatted_chunk)
              if result.get('ok'):
                  print(f"Message {i+1}/{len(chunks)} sent successfully")
              else:
                  print(f"Failed to send message {i+1}: {result}")

          print("Report sent to Telegram!")
          EOF

      - name: Send report as document to Telegram
        run: |
          curl -F "chat_id=${{ secrets.TELEGRAM_CHANNEL_ID }}" \
               -F "document=@google_trends_report.txt" \
               -F "caption=AI & Small Business UK Trends - $(date '+%Y-%m-%d')" \
               "https://api.telegram.org/bot${{ secrets.TELEGRAM_BOT_TOKEN }}/sendDocument"

      - name: Upload results as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: google-trends-ai-uk-report
          path: |
            *.txt
            *.csv
            *.json
          retention-days: 30
          if-no-files-found: ignore
